{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and Preprocessing Data\n",
      "inside h5 format\n",
      "Keys in file: ['X', 'Y']\n",
      "=== DATA: ===\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]]\n",
      "\n",
      "\n",
      "=== DATA AFTER: ===\n",
      "[[-0.33427826 -0.35183723 -0.35727728 ...  0.08506461  0.19411842\n",
      "  -0.66443265]\n",
      " [-0.33427826 -0.35183723 -0.35727728 ... -0.87155712  0.47428055\n",
      "   0.60681282]\n",
      " [-0.33427826 -0.35183723 -0.35727728 ...  2.17525911 -0.87431899\n",
      "  -0.66443265]\n",
      " ...\n",
      " [-0.33427826 -0.35183723 -0.35727728 ... -0.87155712  0.24852136\n",
      "   0.22669642]\n",
      " [-0.33427826 -0.35183723 -0.35727728 ...  1.09703078 -0.33337379\n",
      "  -0.66443265]\n",
      " [-0.33427826 -0.35183723 -0.35727728 ...  0.92421636  0.27599096\n",
      "  -0.66443265]]\n",
      "\n",
      "\n",
      "Defining and Training Model\n",
      "Obtaining Embeddings\n",
      "Clustering\n",
      "Clustering Evaluation: ARI=0.3743, NMI=0.5256\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "from data_loader import load_data, preprocess\n",
    "from model import Autoencoder, ClusteringLayer \n",
    "from trainer import train, get_embeddings\n",
    "from cluster import cluster_embeddings, evaluate_cluster\n",
    "import torch\n",
    "\n",
    "def main(filepath, file_format, n_clusters, encoding_dim, epochs, learning_rate, batch_size, normalize, scale, log_transform, n_top_genes):\n",
    "\n",
    "    #Load and Preprocess Data\n",
    "    print(\"Loading and Preprocessing Data\")\n",
    "    data, labels = load_data(filepath, format=file_format)\n",
    "    if data is None:\n",
    "        print(\"Failed to load data. Exiting.\")\n",
    "        return\n",
    "    processed_data, scaler = preprocess(data, normalize, scale, log_transform, n_top_genes)\n",
    "    input_dim = processed_data.shape[1]\n",
    "\n",
    "    #define and train Model\n",
    "    print(\"Defining and Training Model\")\n",
    "    autoencoder = Autoencoder(input_dim, encoding_dim).to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")) # move to device\n",
    "    clustering_layer = ClusteringLayer(n_clusters, encoding_dim).to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "    #use the train function\n",
    "    trained_model = train(autoencoder, clustering_layer, processed_data, epochs, batch_size, learning_rate, n_clusters) \n",
    "\n",
    "    #get embeddings\n",
    "    print(\"Obtaining Embeddings\")\n",
    "    embeddings = get_embeddings(autoencoder, processed_data) # Add .cpu().numpy()\n",
    "\n",
    "    #clustering\n",
    "    print(\"Clustering\")\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    cluster_labels = clustering_layer(torch.tensor(embeddings, dtype=torch.float32).to(device)).argmax(1).cpu().numpy()\n",
    "\n",
    "    #eval\n",
    "    if labels is not None:  #real labels if available\n",
    "        true_labels = labels\n",
    "    else:\n",
    "        true_labels = np.random.randint(0, n_clusters, embeddings.shape[0]) #otherwise use placeholder\n",
    "\n",
    "    evaluation_results = evaluate_cluster(true_labels, cluster_labels)\n",
    "    print(f\"Clustering Evaluation: ARI={evaluation_results['ARI']:.4f}, NMI={evaluation_results['NMI']:.4f}\")\n",
    "    return cluster_labels, embeddings, scaler\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    filepath = 'scDeepClustering_Sample_Data/mouse_bladder_cell_select_2100.h5'\n",
    "    # filepath = 'Splatter_Sim_Data/splatter_simulate_data_1.h5'\n",
    "    file_format = 'h5'\n",
    "    n_clusters = 3\n",
    "    encoding_dim = 32\n",
    "    epochs = 100\n",
    "    learning_rate = 0.001\n",
    "    batch_size = 32\n",
    "    normalize = True\n",
    "    scale = True\n",
    "    log_transform = True\n",
    "    n_top_genes = 2000\n",
    "\n",
    "    main(filepath, file_format, n_clusters, encoding_dim, epochs, learning_rate, batch_size, normalize, scale, log_transform, n_top_genes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.15 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "bd385fe162c5ca0c84973b7dd5c518456272446b2b64e67c2a69f949ca7a1754"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
